{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras Convolutional Neural Networks",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RFajardoMonzon/MachineLearningCourse/blob/master/Keras_Convolutional_Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AiATNn-i-Qi",
        "colab_type": "text"
      },
      "source": [
        "# Notebook 11 - Redes Neuronales Convolucionales.\n",
        "\n",
        "*   Recuerda que puedes consultar la documentación sobre una función escribiendo **?** justo después de la función: *Ejemplo: np.maximum?*\n",
        "*   Puedes ejecutar el contenido de una celda con el atajo de teclado **CTRL+ENTER**\n",
        "*   Utiliza **TAB** cada vez que quieras autocompletar una llamada a una función.\n",
        "*   Puedes ejecutar instrucciones de bash directamente desde el notebook usando **!** : *Ejemplo: !pip install tensorflow*\n",
        "*   Recuerda que Google es tu amigo, y saber buscar la información en las documentaciones de las librerías es muy importante.\n",
        "*   Una solución correcta no es la que funciona sino la que se entiende!\n",
        "*   No dudes en preguntar cualquier duda al profesor que lleva todo el día dando la turra."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESaZnccukB3p",
        "colab_type": "text"
      },
      "source": [
        "## 1. Diseñando nuestra primera CNN\n",
        "\n",
        "Vaya turra estar trabajando siempre con el mismo dataset de números... ¿verdad? Pues venga, aquí vamos otra vez. Hoy rápidamente vamos a comprobar si nos aporta alguna mejora trabajar con una Red Neuronal Convolucional en cuestión de rendimiento sobre el dataset de MNIST, comparado con nuestra Red Neuronal Multicapa de ayer.\n",
        "\n",
        "---\n",
        "\n",
        "**Tu tarea:** Diseña, entrena y evalua, con Keras una *Red Neuronal Convolucional* con el dataset MNIST Aumentado generado en el ejercicio de ayer (ya se proporciona el código para aumentar los datos). Comprueba si esta arquitectura mejora el rendimiento obtenido en comparación con la *Red Neuronal Multicapa.* Para ello, obtén métricas del rendimiento de la red para tu ***test_set Aumentado*** con la red entrenada ***sin*** y ***con*** datos aumentados (mismo ejercicio de ayer). ¿Existen diferencias en los resultados del experimento?  Igualmente, compara el número de parámetros utilizados por ambas redes. ¿Cuál utiliza un menor número de parámetros? (recuerda la función ***model.summary()***).\n",
        "\n",
        "**Importante:** Recuerda cambiar el Entorno de ejecución en la pestaña *Entorno de ejecución* >  *Cambiar tipo de entorno de ejecución* el *Acelerador por Hardware* de ***None*** a ***GPU***, para que el rendimiento de entrenamiento sea superior."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYV6UPR-7NAX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFDIbRQMlHU2",
        "colab_type": "code",
        "outputId": "c633172a-89c1-44ef-89d8-2876ac03766c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import numpy as np\n",
        "import scipy as sc\n",
        "import sklearn as sk\n",
        "import pandas  as pd\n",
        "import seaborn as sb\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy.random\n",
        "\n",
        "from scipy.ndimage import shift\n",
        "from scipy.ndimage import rotate\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.utils  import to_categorical\n",
        "\n",
        "# Cargamos el dataset desde el archivo.\n",
        "mnist = pd.read_csv(\"./sample_data/mnist_train_small.csv\", header=None).as_matrix()\n",
        "\n",
        "# Guardamos las variables X e Y.\n",
        "X, Y = mnist[:, 1:], mnist[:, 0:1]\n",
        "\n",
        "# Normalizamos input y codificamos output con one-hot encoding.\n",
        "Xt = X / 255.0\n",
        "Yt = to_categorical(Y, 10)\n",
        "\n",
        "# Generamos train y test set.\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(Xt, Yt, train_size=0.7)\n",
        "\n",
        "def traslate_imgs(X):\n",
        "  \n",
        "  # Matriz resultado.\n",
        "  trasl_X = np.zeros(X.shape)\n",
        "  \n",
        "  for ix, x in enumerate(X):\n",
        "    \n",
        "    # Convertimos a matriz el vector de píxeles.\n",
        "    rx = x.reshape(28, 28)\n",
        "    #r Seleccionamos cuánto vamos a cortar en X e Y.\n",
        "    shift_x = np.random.randint(14) - 7\n",
        "    shift_y = np.random.randint(14) - 7\n",
        "    # Guardamos la traslación de la imagen.\n",
        "    trasl_X[ix] = shift(x.reshape(28, 28), (shift_x, shift_y)).flatten()\n",
        "    \n",
        "  return trasl_X\n",
        "\n",
        "\n",
        "def rotate_imgs(X):\n",
        "  \n",
        "  # Matriz resultado.\n",
        "  rot_X = np.zeros(X.shape)\n",
        "  \n",
        "  for ix, x in enumerate(X):\n",
        "    \n",
        "    # Convertimos a matriz el vector de píxeles.\n",
        "    rx = x.reshape(28, 28)\n",
        "    # Seleccionamos el ángulo con el que rotar la imagen.\n",
        "    angle = np.random.randint(180) - 90\n",
        "    # Guardamos la traslación de la imagen.\n",
        "    rot_X[ix] = rotate(x.reshape(28, 28), angle, reshape=False, prefilter=False, order=1).flatten()\n",
        "    \n",
        "  return rot_X\n",
        "\n",
        "\n",
        "def noise_imgs(X, noise_level=0.5):\n",
        "  \n",
        "  # Matriz resultado.\n",
        "  nois_X = np.zeros(X.shape)\n",
        "  \n",
        "  for ix, x in enumerate(X):\n",
        "    \n",
        "    # Convertimos a matriz el vector de píxeles.\n",
        "    rx = x.reshape(28, 28)\n",
        "    # Seleccionamos el ángulo con el que rotar la imagen.\n",
        "    noise = (np.random.random(x.shape) * 2.0  - 1) * noise_level\n",
        "    # Guardamos la traslación de la imagen.\n",
        "    nois_X[ix] = np.clip(x + noise, 0.0, 1.0).flatten()\n",
        "    \n",
        "  return nois_X\n",
        "\n",
        "def augmentDataset(X, Y):\n",
        "\n",
        "  # Generamos train trasladada.\n",
        "  trasX = traslate_imgs(X)\n",
        "  # Generamos train rotada.\n",
        "  rotaX = rotate_imgs(X)\n",
        "  # Generamos train con ruido 50%.\n",
        "  no50X = noise_imgs(X, 0.5)\n",
        "  # Generamos train con ruido 25%.\n",
        "  no25X = noise_imgs(X, 0.25)\n",
        "\n",
        "  # Juntamos todos los sets.\n",
        "  augmX = np.vstack([X, \n",
        "                    trasX, \n",
        "                    rotaX, \n",
        "                    no50X, \n",
        "                    no25X])\n",
        "\n",
        "  # E incrementamos el vector Y por 5 veces.\n",
        "  augmY = np.tile(Y, (5,1))\n",
        "  \n",
        "  return augmX.reshape(augmX.shape[0], 28, 28, 1), augmY\n",
        "\n",
        "augmX_train, augmY_train = augmentDataset(X_train, Y_train)\n",
        "augmX_test,  augmY_test  = augmentDataset(X_test, Y_test)\n",
        "\n",
        "print(X_train.shape, augmX_train.shape)\n",
        "print(X_test.shape,  augmX_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(14000, 784) (70000, 28, 28, 1)\n",
            "(6000, 784) (30000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "7e40dbb9-dcfe-4cc4-d314-e233ba7ed96a",
        "id": "1Gpbu8_5He6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        }
      },
      "source": [
        "# Visualizamos los datos generados.\n",
        "idx = 100\n",
        "\n",
        "fig, axs = plt.subplots(1,5,figsize=(12,12))\n",
        "\n",
        "axs[0].matshow(augmX_train[idx + len(X_train) * 0,:].reshape(28, 28))\n",
        "axs[1].matshow(augmX_train[idx + len(X_train) * 1,:].reshape(28, 28))\n",
        "axs[2].matshow(augmX_train[idx + len(X_train) * 2,:].reshape(28, 28))\n",
        "axs[3].matshow(augmX_train[idx + len(X_train) * 3,:].reshape(28, 28))\n",
        "axs[4].matshow(augmX_train[idx + len(X_train) * 4,:].reshape(28, 28))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f0688e8db38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsMAAACWCAYAAAA7UIUvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 864x864 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQp7LNDVlheG",
        "colab_type": "code",
        "outputId": "e0291ad2-4cb1-4d72-cdfe-6a0d8b5d6b62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1071
        }
      },
      "source": [
        "## Importamos Keras API\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import InputLayer, Input\n",
        "from tensorflow.python.keras.layers import Reshape, MaxPooling2D\n",
        "from tensorflow.python.keras.layers import Conv2D, Dense, Flatten, ReLU, BatchNormalization\n",
        "\n",
        "### COMIENZA TU CÓDIGO AQUÍ ###\n",
        "\n",
        "X_train_reshaped = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
        "X_test_reshaped = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
        "\n",
        "print(X_train_reshaped.shape)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\", input_shape=(28, 28, 1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation=\"relu\"))\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
        "\n",
        "model.fit(X_train_reshaped, Y_train, validation_data=(augmX_test, augmY_test),\n",
        "          batch_size=20, epochs=30)\n",
        "\n",
        "model.save(\"models/normal_data.h5\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(14000, 28, 28, 1)\n",
            "Train on 14000 samples, validate on 30000 samples\n",
            "Epoch 1/30\n",
            "14000/14000 [==============================] - 6s 408us/sample - loss: 0.2656 - acc: 0.9139 - val_loss: 1.2278 - val_acc: 0.7410\n",
            "Epoch 2/30\n",
            "14000/14000 [==============================] - 5s 388us/sample - loss: 0.0731 - acc: 0.9769 - val_loss: 1.1123 - val_acc: 0.7788\n",
            "Epoch 3/30\n",
            "14000/14000 [==============================] - 6s 412us/sample - loss: 0.0429 - acc: 0.9859 - val_loss: 1.2583 - val_acc: 0.7806\n",
            "Epoch 4/30\n",
            "14000/14000 [==============================] - 6s 443us/sample - loss: 0.0334 - acc: 0.9885 - val_loss: 1.1593 - val_acc: 0.7704\n",
            "Epoch 5/30\n",
            "14000/14000 [==============================] - 5s 392us/sample - loss: 0.0252 - acc: 0.9915 - val_loss: 1.3403 - val_acc: 0.7793\n",
            "Epoch 6/30\n",
            "14000/14000 [==============================] - 5s 388us/sample - loss: 0.0227 - acc: 0.9929 - val_loss: 1.4191 - val_acc: 0.7967\n",
            "Epoch 7/30\n",
            "14000/14000 [==============================] - 5s 386us/sample - loss: 0.0192 - acc: 0.9947 - val_loss: 1.2903 - val_acc: 0.7937\n",
            "Epoch 8/30\n",
            "14000/14000 [==============================] - 5s 388us/sample - loss: 0.0163 - acc: 0.9943 - val_loss: 1.4910 - val_acc: 0.7963\n",
            "Epoch 9/30\n",
            "14000/14000 [==============================] - 5s 388us/sample - loss: 0.0120 - acc: 0.9954 - val_loss: 1.6035 - val_acc: 0.7771\n",
            "Epoch 10/30\n",
            "14000/14000 [==============================] - 5s 385us/sample - loss: 0.0165 - acc: 0.9937 - val_loss: 1.3584 - val_acc: 0.7992\n",
            "Epoch 11/30\n",
            "14000/14000 [==============================] - 5s 390us/sample - loss: 0.0109 - acc: 0.9961 - val_loss: 1.5254 - val_acc: 0.7859\n",
            "Epoch 12/30\n",
            "14000/14000 [==============================] - 5s 386us/sample - loss: 0.0120 - acc: 0.9962 - val_loss: 1.6136 - val_acc: 0.7778\n",
            "Epoch 13/30\n",
            "14000/14000 [==============================] - 5s 388us/sample - loss: 0.0056 - acc: 0.9982 - val_loss: 1.5682 - val_acc: 0.8041\n",
            "Epoch 14/30\n",
            "14000/14000 [==============================] - 5s 385us/sample - loss: 0.0025 - acc: 0.9992 - val_loss: 1.7677 - val_acc: 0.7917\n",
            "Epoch 15/30\n",
            "14000/14000 [==============================] - 5s 388us/sample - loss: 0.0155 - acc: 0.9949 - val_loss: 1.5173 - val_acc: 0.7952\n",
            "Epoch 16/30\n",
            "14000/14000 [==============================] - 5s 387us/sample - loss: 0.0115 - acc: 0.9967 - val_loss: 1.3943 - val_acc: 0.7959\n",
            "Epoch 17/30\n",
            "14000/14000 [==============================] - 5s 388us/sample - loss: 0.0060 - acc: 0.9979 - val_loss: 1.5490 - val_acc: 0.8006\n",
            "Epoch 18/30\n",
            "14000/14000 [==============================] - 6s 439us/sample - loss: 0.0105 - acc: 0.9970 - val_loss: 1.4748 - val_acc: 0.7972\n",
            "Epoch 19/30\n",
            "14000/14000 [==============================] - 6s 425us/sample - loss: 0.0040 - acc: 0.9984 - val_loss: 1.6675 - val_acc: 0.7978\n",
            "Epoch 20/30\n",
            "14000/14000 [==============================] - 5s 387us/sample - loss: 0.0035 - acc: 0.9988 - val_loss: 1.7786 - val_acc: 0.7906\n",
            "Epoch 21/30\n",
            "14000/14000 [==============================] - 5s 386us/sample - loss: 0.0118 - acc: 0.9969 - val_loss: 1.6376 - val_acc: 0.8032\n",
            "Epoch 22/30\n",
            "14000/14000 [==============================] - 5s 384us/sample - loss: 0.0029 - acc: 0.9991 - val_loss: 1.8106 - val_acc: 0.7988\n",
            "Epoch 23/30\n",
            "14000/14000 [==============================] - 5s 386us/sample - loss: 0.0116 - acc: 0.9971 - val_loss: 1.7691 - val_acc: 0.7993\n",
            "Epoch 24/30\n",
            "14000/14000 [==============================] - 5s 384us/sample - loss: 0.0056 - acc: 0.9981 - val_loss: 1.9405 - val_acc: 0.7984\n",
            "Epoch 25/30\n",
            "14000/14000 [==============================] - 5s 384us/sample - loss: 0.0101 - acc: 0.9969 - val_loss: 1.6191 - val_acc: 0.8044\n",
            "Epoch 26/30\n",
            "14000/14000 [==============================] - 5s 385us/sample - loss: 4.8258e-04 - acc: 0.9999 - val_loss: 1.8496 - val_acc: 0.8074\n",
            "Epoch 27/30\n",
            "14000/14000 [==============================] - 5s 385us/sample - loss: 0.0069 - acc: 0.9980 - val_loss: 2.2134 - val_acc: 0.7790\n",
            "Epoch 28/30\n",
            "14000/14000 [==============================] - 5s 386us/sample - loss: 0.0058 - acc: 0.9984 - val_loss: 2.0561 - val_acc: 0.7926\n",
            "Epoch 29/30\n",
            "14000/14000 [==============================] - 5s 386us/sample - loss: 0.0108 - acc: 0.9971 - val_loss: 1.7225 - val_acc: 0.8049\n",
            "Epoch 30/30\n",
            "14000/14000 [==============================] - 5s 384us/sample - loss: 2.2282e-04 - acc: 0.9999 - val_loss: 1.7641 - val_acc: 0.8078\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7GD8ndnCQkz",
        "colab_type": "code",
        "outputId": "0714684e-bed5-4f26-8f48-a90b5327cdd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1054
        }
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\", input_shape=(28, 28, 1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation=\"relu\"))\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
        "\n",
        "model.fit(augmX_train, augmY_train, validation_data=(augmX_test, augmY_test),\n",
        "          batch_size=20, epochs=30)\n",
        "\n",
        "model.save(\"models/augm_data.h5\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 70000 samples, validate on 30000 samples\n",
            "Epoch 1/30\n",
            "70000/70000 [==============================] - 18s 260us/sample - loss: 0.2593 - acc: 0.9194 - val_loss: 0.1187 - val_acc: 0.9636\n",
            "Epoch 2/30\n",
            "70000/70000 [==============================] - 20s 281us/sample - loss: 0.0805 - acc: 0.9747 - val_loss: 0.0829 - val_acc: 0.9748\n",
            "Epoch 3/30\n",
            "70000/70000 [==============================] - 19s 277us/sample - loss: 0.0532 - acc: 0.9824 - val_loss: 0.0795 - val_acc: 0.9756\n",
            "Epoch 4/30\n",
            "70000/70000 [==============================] - 18s 255us/sample - loss: 0.0362 - acc: 0.9877 - val_loss: 0.1055 - val_acc: 0.9713\n",
            "Epoch 5/30\n",
            "70000/70000 [==============================] - 18s 255us/sample - loss: 0.0290 - acc: 0.9903 - val_loss: 0.1028 - val_acc: 0.9730\n",
            "Epoch 6/30\n",
            "70000/70000 [==============================] - 18s 255us/sample - loss: 0.0233 - acc: 0.9923 - val_loss: 0.1174 - val_acc: 0.9705\n",
            "Epoch 7/30\n",
            "70000/70000 [==============================] - 19s 270us/sample - loss: 0.0201 - acc: 0.9935 - val_loss: 0.0976 - val_acc: 0.9756\n",
            "Epoch 8/30\n",
            "70000/70000 [==============================] - 18s 258us/sample - loss: 0.0180 - acc: 0.9943 - val_loss: 0.1240 - val_acc: 0.9746\n",
            "Epoch 9/30\n",
            "70000/70000 [==============================] - 18s 254us/sample - loss: 0.0155 - acc: 0.9949 - val_loss: 0.1186 - val_acc: 0.9758\n",
            "Epoch 10/30\n",
            "70000/70000 [==============================] - 18s 254us/sample - loss: 0.0161 - acc: 0.9952 - val_loss: 0.1040 - val_acc: 0.9790\n",
            "Epoch 11/30\n",
            "70000/70000 [==============================] - 18s 253us/sample - loss: 0.0171 - acc: 0.9948 - val_loss: 0.1145 - val_acc: 0.9772\n",
            "Epoch 12/30\n",
            "70000/70000 [==============================] - 19s 274us/sample - loss: 0.0130 - acc: 0.9961 - val_loss: 0.1242 - val_acc: 0.9759\n",
            "Epoch 13/30\n",
            "70000/70000 [==============================] - 18s 254us/sample - loss: 0.0135 - acc: 0.9959 - val_loss: 0.1470 - val_acc: 0.9769\n",
            "Epoch 14/30\n",
            "70000/70000 [==============================] - 18s 253us/sample - loss: 0.0148 - acc: 0.9956 - val_loss: 0.1266 - val_acc: 0.9767\n",
            "Epoch 15/30\n",
            "70000/70000 [==============================] - 18s 253us/sample - loss: 0.0114 - acc: 0.9967 - val_loss: 0.1283 - val_acc: 0.9778\n",
            "Epoch 16/30\n",
            "70000/70000 [==============================] - 19s 272us/sample - loss: 0.0137 - acc: 0.9962 - val_loss: 0.1411 - val_acc: 0.9777\n",
            "Epoch 17/30\n",
            "70000/70000 [==============================] - 18s 254us/sample - loss: 0.0107 - acc: 0.9968 - val_loss: 0.1805 - val_acc: 0.9726\n",
            "Epoch 18/30\n",
            "70000/70000 [==============================] - 18s 254us/sample - loss: 0.0107 - acc: 0.9970 - val_loss: 0.1402 - val_acc: 0.9795\n",
            "Epoch 19/30\n",
            "70000/70000 [==============================] - 20s 280us/sample - loss: 0.0130 - acc: 0.9966 - val_loss: 0.1467 - val_acc: 0.9788\n",
            "Epoch 20/30\n",
            "70000/70000 [==============================] - 19s 274us/sample - loss: 0.0122 - acc: 0.9967 - val_loss: 0.1566 - val_acc: 0.9780\n",
            "Epoch 21/30\n",
            "70000/70000 [==============================] - 19s 267us/sample - loss: 0.0127 - acc: 0.9970 - val_loss: 0.1454 - val_acc: 0.9790\n",
            "Epoch 22/30\n",
            "70000/70000 [==============================] - 18s 254us/sample - loss: 0.0135 - acc: 0.9968 - val_loss: 0.1665 - val_acc: 0.9786\n",
            "Epoch 23/30\n",
            "70000/70000 [==============================] - 18s 254us/sample - loss: 0.0097 - acc: 0.9973 - val_loss: 0.1574 - val_acc: 0.9782\n",
            "Epoch 24/30\n",
            "70000/70000 [==============================] - 18s 255us/sample - loss: 0.0118 - acc: 0.9970 - val_loss: 0.1699 - val_acc: 0.9769\n",
            "Epoch 25/30\n",
            "70000/70000 [==============================] - 19s 274us/sample - loss: 0.0129 - acc: 0.9972 - val_loss: 0.2007 - val_acc: 0.9757\n",
            "Epoch 26/30\n",
            "70000/70000 [==============================] - 18s 254us/sample - loss: 0.0139 - acc: 0.9971 - val_loss: 0.1980 - val_acc: 0.9776\n",
            "Epoch 27/30\n",
            "70000/70000 [==============================] - 18s 254us/sample - loss: 0.0104 - acc: 0.9977 - val_loss: 0.1786 - val_acc: 0.9775\n",
            "Epoch 28/30\n",
            "70000/70000 [==============================] - 18s 253us/sample - loss: 0.0107 - acc: 0.9976 - val_loss: 0.2170 - val_acc: 0.9751\n",
            "Epoch 29/30\n",
            "70000/70000 [==============================] - 19s 266us/sample - loss: 0.0153 - acc: 0.9968 - val_loss: 0.1789 - val_acc: 0.9800\n",
            "Epoch 30/30\n",
            "70000/70000 [==============================] - 18s 261us/sample - loss: 0.0104 - acc: 0.9975 - val_loss: 0.1966 - val_acc: 0.9777\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dh0Is82PPCA",
        "colab_type": "code",
        "outputId": "1be3164f-c886-4ed9-9e9c-617519b6f43d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model = load_model(\"models/normal_data.h5\")\n",
        "\n",
        "model.evaluate(augmX_test[:X_test.shape[0]*2], augmY_test[:Y_test.shape[0]*2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20000/20000 [==============================] - 1s 69us/sample - loss: 2.6035 - acc: 0.7224\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.6035491574140424, 0.72235]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUGxsrOCo6cM",
        "colab_type": "text"
      },
      "source": [
        "## 2. (OPCIONAL) Clasificando imágenes reales (CIFAR100 - Dataset)\n",
        "\n",
        "---\n",
        "\n",
        "**Tu tarea:**  Una vez ya hemos aprendido a clasificar imágenes de MNIST con una Red Neuronal Convolucional (CNN), no será complicado generalizar nuestro problema a otros datasets más complejos. En este ejercicio probarás a diseñar, entrenar y evaluar a una CNN entrenada en el dataset CIFAR100, para 100 clases de objetos diferentes de imágenes a color (ten en cuenta esto para la definición de las dimensiones). Todo el código implementado ayer para aumentar el dataset, puede ser sustituido por unas pocas lineas de código que hagan uso de la función ***ImageDataGenerator(...)***. Prueba también a aumentar tu dataset haciendo uso de esta funcionalidad. *(En este caso la documentación la encontrarás en la web original de Keras y no en la de Tensorflow.)*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZEBjEVttkYT",
        "colab_type": "code",
        "outputId": "ea7d684c-dfa9-4fbb-c56a-148b5434f51c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import numpy as np\n",
        "import scipy as sc\n",
        "import sklearn as sk\n",
        "import pandas  as pd\n",
        "import seaborn as sb\n",
        "\n",
        "from tensorflow.keras.utils  import to_categorical\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy.random\n",
        "\n",
        "from scipy.ndimage import shift\n",
        "from scipy.ndimage import rotate\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.datasets import cifar100\n",
        "\n",
        "(X_train_raw, Y_train_raw), (X_test_raw, Y_test_raw) = cifar100.load_data()\n",
        "\n",
        "Y_train = to_categorical(Y_train_raw, 100)\n",
        "Y_test = to_categorical(Y_test_raw, 100)\n",
        "\n",
        "X_train = X_train_raw / 255.\n",
        "X_test = X_test_raw / 255.\n",
        "\n",
        "# print(X_train.shape)\n",
        "\n",
        "\n",
        "\n",
        "# train_generator = generator.flow(X_train_reshaped, Y_train)\n",
        "# val_generator = generator.flow(X_test.reshape(X_test.shape[0], 28, 28, 1), Y_test)\n",
        "\n",
        "# print(X_test)\n",
        "# print(Y_test)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 53s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tf7u7lwQlZ_m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "generator = ImageDataGenerator(rotation_range=90, width_shift_range=0.25,\n",
        "                               height_shift_range=0.25)\n",
        "\n",
        "generator.fit(X_train)\n",
        "\n",
        "train_generator = generator.flow(X_train, Y_train)\n",
        "val_generator = generator.flow(X_test, Y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKue1kvLIUKp",
        "colab_type": "code",
        "outputId": "8a7f8c4f-7fdc-4807-8380-f9b2394e0eb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "from tensorflow.keras.backend import clear_session\n",
        "from tensorflow.keras.layers import Activation, Dropout\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import InputLayer, Input\n",
        "from tensorflow.keras.layers import Reshape, MaxPooling2D\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Flatten, ReLU, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "clear_session()\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# model.add(Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\", input_shape=X_train.shape[1:]))\n",
        "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# model.add(Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\"))\n",
        "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# model.add(Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\"))\n",
        "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# model.add(Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\"))\n",
        "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# model.add(Flatten())\n",
        "\n",
        "# model.add(Dense(1024, activation=\"relu\"))\n",
        "# model.add(Dense(100, activation=\"softmax\"))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding='same',\n",
        "    input_shape=X_train.shape[1:]))\n",
        "model.add(Activation('elu'))\n",
        "model.add(Conv2D(128, (3, 3)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), padding='same'))\n",
        "model.add(Activation('elu'))\n",
        "model.add(Conv2D(256, (3, 3)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), padding='same'))\n",
        "model.add(Activation('elu'))\n",
        "model.add(Conv2D(512, (3, 3)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024))\n",
        "model.add(Activation('elu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(100))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
        "\n",
        "model.fit_generator(train_generator, validation_data=val_generator, epochs=30)\n",
        "\n",
        "model.save(\"models/cifar100.h5\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 15.9572 - acc: 0.0100\n",
            "1563/1563 [==============================] - 45s 29ms/step - loss: 5.2851 - acc: 0.0299 - val_loss: 15.9572 - val_acc: 0.0100\n",
            "Epoch 2/30\n",
            " 272/1563 [====>.........................] - ETA: 31s - loss: 15.9533 - acc: 0.0102"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-5d01e112a131>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"categorical_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"acc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"models/cifar100.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1424\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1426\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m   def evaluate_generator(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m       \u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1189\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}